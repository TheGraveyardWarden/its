**زمان‌بندی رشته‌های مستقل**
معماری ولتا به گونه‌ای طراحی شده است که برنامه‌نویسی آن نسبت به GPU‌های قبلی بسیار آسان‌تر باشد، به طوری که کاربران قادر به کار مؤثرتر بر روی برنامه‌های پیچیده‌تر و متنوع‌تر خواهند بود. Volta GV100 اولین GPU است که از زمان‌بندی مستقل رشته‌ها پشتیبانی می‌کند، که این امکان را می‌دهد تا هم‌زمانی و همکاری دقیق‌تری بین رشته‌های موازی در یک برنامه برقرار شود. یکی از اهداف اصلی طراحی ولتا این بود که تلاش مورد نیاز برای راه‌اندازی برنامه‌ها روی GPU را کاهش دهد و انعطاف‌پذیری بیشتری در همکاری رشته‌ها فراهم کند، که منجر به افزایش کارایی در الگوریتم‌های موازی با دقت بالا خواهد شد.

مدل‌های SIMT GPUهای قبلی NVIDIA
GPU های Pascal و مدل‌های پیشین NVIDIA گروه‌هایی از 32 رشته (که به آن‌ها warp گفته می‌شود) را به صورت SIMT (دستور واحد، چندین رشته) اجرا می‌کنند. در warp پَسکال، یک شمارنده برنامه واحد وجود دارد که بین تمام 32 رشته به اشتراک گذاشته می‌شود، همراه با یک ماسک فعال که مشخص می‌کند کدام رشته‌ها در هر لحظه از زمان فعال هستند. این بدین معنی است که مسیرهای اجرای واگرایانه باعث غیرفعال شدن برخی از رشته‌ها می‌شوند و اجرای بخش‌های مختلف warp را به صورت سریال انجام می‌دهند، همان‌طور که در شکل 20 نشان داده شده است. ماسک اصلی تا زمانی که warp دوباره به هم بپیوندد، ذخیره می‌شود، که معمولاً در پایان بخش واگرا رخ می‌دهد و در این لحظه ماسک بازیابی می‌شود و رشته‌ها دوباره به طور همزمان اجرا می‌شوند.

مدل اجرای SIMT پَسکال با کاهش تعداد منابع مورد نیاز برای ردیابی وضعیت رشته‌ها و با بازگشت سریع رشته‌ها به حالت همگرا برای حداکثر کردن موازی‌سازی، کارایی را به حداکثر می‌رساند. با این حال، ردیابی وضعیت رشته‌ها به صورت کلی برای تمام warp، بدین معنی است که وقتی مسیر اجرای برنامه واگرا می‌شود، رشته‌هایی که شاخه‌های متفاوتی را دنبال می‌کنند، همزمانی خود را از دست می‌دهند تا زمانی که دوباره به هم بپیوندند. این از دست دادن همزمانی باعث می‌شود که رشته‌ها در نواحی واگرا یا وضعیت‌های مختلف اجرای برنامه نتوانند یکدیگر را سیگنال کنند یا داده‌ای را تبادل کنند. این مسئله باعث بروز ناسازگاری می‌شود که در آن رشته‌ها از warps مختلف به صورت همزمان اجرا می‌شوند، اما رشته‌های واگرا از یک warp به صورت دنباله‌وار اجرا می‌شوند تا زمانی که دوباره به هم بپیوندند. این بدین معنی است که به عنوان مثال، الگوریتم‌هایی که نیاز به اشتراک‌گذاری دقیق داده‌ها تحت قفل‌ها یا mutex‌ها دارند، بسته به این‌که رشته‌های متنازع از کدام warp می‌آیند، می‌توانند به راحتی به بن‌بست (Deadlock) منتهی شوند. بنابراین، در GPUهای پَسکال و مدل‌های پیشین، برنامه‌نویسان باید از هم‌زمانی دقیق اجتناب کنند یا به الگوریتم‌های بدون قفل یا آگاه از warp تکیه کنند.

مدل SIMT ولتا
ولتا این تصویر را با ایجاد همزمانی برابر بین تمام رشته‌ها، بدون توجه به warp، تغییر می‌دهد. این کار را با حفظ وضعیت اجرای هر رشته، از جمله شمارنده برنامه و پشته فراخوانی، انجام می‌دهد، همان‌طور که در شکل 21 نشان داده شده است.

زمان‌بندی مستقل رشته‌ها در ولتا به GPU این امکان را می‌دهد که اجرای هر رشته‌ای را متوقف کند، چه برای استفاده بهتر از منابع اجرایی و چه برای این‌که یک رشته منتظر تولید داده توسط رشته دیگر باشد. برای حداکثر کردن کارایی موازی، ولتا یک بهینه‌ساز زمان‌بندی دارد که تعیین می‌کند چگونه رشته‌های فعال از همان warp باید به واحدهای SIMT گروه‌بندی شوند. این به ولتا اجازه می‌دهد که از توان بالای اجرای SIMT مشابه GPU‌های قبلی NVIDIA بهره ببرد، اما با انعطاف‌پذیری بسیار بیشتر: رشته‌ها اکنون می‌توانند در سطح زیر warp واگرا و دوباره به هم بپیوندند، در حالی که بهینه‌ساز همگرایی در ولتا همچنان رشته‌هایی که همان کد را اجرا می‌کنند، در کنار هم گروه‌بندی کرده و آن‌ها را به صورت موازی اجرا می‌کند تا کارایی به حداکثر برسد.

اجرای مثال کد از شکل 20 در ولتا کمی متفاوت به نظر می‌رسد. بیانیه‌های موجود در شاخه‌های if و else در برنامه اکنون می‌توانند به صورت متناوب در زمان اجرا شوند، همان‌طور که در شکل 22 نشان داده شده است. توجه داشته باشید که اجرای برنامه هنوز به صورت SIMT است: در هر چرخه ساعت، هسته‌های CUDA همان دستور را برای تمام رشته‌های فعال در یک warp اجرا می‌کنند، همان‌طور که قبلاً بود، و کارایی اجرایی معماری‌های قبلی حفظ می‌شود. نکته مهم این است که توانایی ولتا در زمان‌بندی مستقل رشته‌ها در یک warp این امکان را فراهم می‌آورد که الگوریتم‌ها و ساختارهای داده پیچیده و دقیق‌تری به روشی طبیعی‌تر پیاده‌سازی شوند. در حالی که زمان‌بند از اجرای مستقل رشته‌ها پشتیبانی می‌کند، کدهایی که به هم‌زمانی نیاز ندارند را بهینه‌سازی می‌کند تا تا حد امکان همگرایی را حفظ کرده و کارایی SIMT را به حداکثر برساند.

جالب است که توجه داشته باشیم که شکل 22 اجرای دستور Z توسط تمام رشته‌ها در warp را به صورت همزمان نشان نمی‌دهد. این به این دلیل است که زمان‌بند باید به طور محافظه‌کارانه فرض کند که Z ممکن است داده‌ای تولید کند که توسط شاخه‌های واگرای دیگر نیاز باشد، در این صورت خودکار بودن همگرایی دوباره خطرناک خواهد بود. در حالت معمولی که A، B، X و Y عملیات هم‌زمان‌سازی ندارند، زمان‌بند می‌تواند شناسایی کند که برای warp بی‌خطر است که به طور طبیعی روی Z دوباره همگرا شود، همان‌طور که در معماری‌های قبلی بود.

برنامه‌ها می‌توانند از تابع جدید هم‌زمان‌سازی warp در CUDA 9، یعنی __syncwarp()، برای اجبار به همگرایی دوباره استفاده کنند، همان‌طور که در شکل 23 نشان داده شده است. در این حالت، بخش‌های واگرای warp ممکن است دستور Z را به صورت همزمان اجرا نکنند، اما تمام مسیرهای اجرایی از رشته‌ها در یک warp قبل از رسیدن به دستور بعد از __syncwarp() تکمیل خواهند شد. به طور مشابه، قرار دادن فراخوانی __syncwarp() قبل از اجرای Z باعث اجبار به همگرایی دوباره قبل از اجرای Z می‌شود، که می‌تواند کارایی SIMT بیشتری را فراهم کند اگر توسعه‌دهنده بداند که این برای برنامه‌اش بی‌خطر است.
